provider: tongyi
model: qwen-long
label: qwen-long
modelType: llm
features:
  - multi-tool-call
  - agent-thought
  - stream-tool-call
modelProperties:
  mode: chat
  contextSize: 10000000
modelParameters:
  - name: temperature
    useTemplate: temperature
    type: float
    defaultValue: 0.3
    min: 0.0
    max: 2.0
    help: 用于控制随机性和多样性的程度。具体来说，temperature值控制了生成文本时对每个候选词的概率分布进行平滑的程度。较高的temperature值会降低概率分布的峰值，使得更多的低概率词被选择，生成结果更加多样化；而较低的temperature值则会增强概率分布的峰值，使得高概率词更容易被选择，生成结果更加确定。
  - name: max_tokens
    useTemplate: max_tokens
    type: int
    defaultValue: 2000
    min: 1
    max: 2000
    help: 用于指定模型在生成内容时token的最大数量，它定义了生成的上限，但不保证每次都会生成到这个数量。
  - name: top_p
    useTemplate: top_p
    type: float
    defaultValue: 0.8
    min: 0.1
    max: 0.9
    help: 生成过程中核采样方法概率阈值，例如，取值为0.8时，仅保留概率加起来大于等于0.8的最可能token的最小集合作为候选集。取值范围为（0,1.0)，取值越大，生成的随机性越高；取值越低，生成的确定性越高。
  - name: top_k
    type: int
    min: 0
    max: 99
    label: 取样数量
    help: 生成时，采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。
  - name: seed
    required: false
    type: int
    defaultValue: 1234
    label: 随机种子
    help: 生成时使用的随机数种子，用户控制模型生成内容的随机性。支持无符号64位整数，默认值为 1234。在使用seed时，模型将尽可能生成相同或相似的结果，但目前不保证每次生成的结果完全相同。
  - name: repetition_penalty
    required: false
    type: float
    defaultValue: 1.1
    label: Repetition penalty
    help: 用于控制模型生成时的重复度。提高repetition_penalty时可以降低模型生成的重复度。1.0表示不做惩罚。
  - name: enable_search
    type: boolean
    defaultValue: false
    help:  模型内置了互联网搜索服务，该参数控制模型在生成文本时是否参考使用互联网搜索结果。启用互联网搜索，模型会将搜索结果作为文本生成过程中的参考信息，但模型会基于其内部逻辑“自行判断”是否使用互联网搜索结果。
  - name: response_format
    useTemplate: response_format
pricing:
  input: '0.0005'
  output: '0.002'
  unit: '0.001'
  currency: RMB
