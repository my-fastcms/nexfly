provider: zhipu
model: chatglm_turbo
label: chatglm_turbo
modelType: chat
modelProperties:
  mode: chat
modelParameters:
  - name: temperature
    useTemplate: temperature
    defaultValue: 0.95
    min: 0.0
    max: 1.0
    help: 采样温度，控制输出的随机性，必须为正数取值范围是：(0.0,1.0]，不能等于 0,默认值为 0.95 值越大，会使输出更随机，更具创造性；值越小，输出会更加稳定或确定建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数。
  - name: top_p
    useTemplate: top_p
    defaultValue: 0.7
    help: 用温度取样的另一种方法，称为核取样取值范围是：(0.0, 1.0) 开区间，不能等于 0 或 1，默认值为 0.7 模型考虑具有 top_p 概率质量tokens的结果例如：0.1 意味着模型解码器只考虑从前 10% 的概率的候选集中取 tokens 建议您根据应用场景调整 top_p 或 temperature 参数，但不要同时调整两个参数。
  - name: incremental
    label: 增量返回
    type: boolean
    help: SSE接口调用时，用于控制每次返回内容方式是增量还是全量，不提供此参数时默认为增量返回，true 为增量返回，false 为全量返回。
    required: false
  - name: return_type
    label: 回复类型
    type: string
    help: 用于控制每次返回内容的类型，空或者没有此字段时默认按照 json_string 返回，json_string 返回标准的 JSON 字符串，text 返回原始的文本内容。
    required: false
    options:
      - text
      - json_string
